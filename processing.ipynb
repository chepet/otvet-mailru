{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import nltk\n",
    "from nltk import corpus\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45571\n"
     ]
    }
   ],
   "source": [
    "folder = 'questions'\n",
    "files = [file for file in os.listdir(folder) if file.endswith('.txt')]\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_questions = []\n",
    "\n",
    "for file in files:\n",
    "    with open(os.path.join(folder, file)) as f:\n",
    "        raw_questions.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save raw, unprocessed questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('raw_questions.txt', 'w') as f:\n",
    "    f.write('\\n'.join(raw_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Кто знает сайты, где можно качать бесплатные mp3?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уберём пунктуацию и стоп-слова\n",
    "\n",
    "1\\. Пунктуация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "punctuation = '\"#$%&\\'()*+/:,-.?!;<=>@[\\]^_`{|}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# questions = [''.join([ch for ch in q if ch not in punctuation]).lower()  for q in raw_questions]\n",
    "# for q in questions[:5]: print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Уберём из предложений также стоп-слова из `nltk.corpus.stopwords.words('russian')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "['во', 'том', 'того', 'со', 'нас', 'вас', 'мне', 'то', 'для', 'моя', 'есть', 'про', 'зачем', 'другой', 'чтобы']\n"
     ]
    }
   ],
   "source": [
    "stopwords = list(set(corpus.stopwords.words('russian')))\n",
    "\n",
    "print(len(stopwords))\n",
    "print(str(stopwords[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_question_to_clean(raw_question, stopwords = stopwords):\n",
    "    \"\"\"\n",
    "    raw_question: str\n",
    "    stopwords: list of str\n",
    "    \n",
    "    returns: str (question without stopwords and punctuation)\n",
    "    e.g:\n",
    "        raw_question = 'С чем будет связана моя будущая работа? кем лучше стать? 25.09.1999'\n",
    "        returns 'связана будущая работа кем стать 25 09 1999'\n",
    "    \"\"\"\n",
    "    \n",
    "    letters_only = re.sub('[^a-zA-Zа-яА-я0-9]', ' ', raw_question) \n",
    "    \n",
    "    words = letters_only.lower().split()                                                  \n",
    "    meaningful_words = [w for w in words if not w in stopwords]   \n",
    "\n",
    "    return(' '.join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = [raw_question_to_clean(q) for q in raw_questions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним почищенные (`questions`) и исходные, необработанные вопросы (`raw_questions`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Кто знает сайты, где можно качать бесплатные mp3?\n",
      "after:  знает сайты качать бесплатные mp3\n",
      "\n",
      "before: почему так часто встречаються люди хамы?\n",
      "after:  почему часто встречаються люди хамы\n",
      "\n",
      "before: Почему ногти на больших пальцах рук растут медленнее, чем на остальных (указательном, среднем, безымянном и мизинце)?\n",
      "after:  почему ногти больших пальцах рук растут медленнее остальных указательном среднем безымянном мизинце\n",
      "\n",
      "before: у кого есть слайд-гитара?\n",
      "after:  кого слайд гитара\n",
      "\n",
      "before: как удалить свой вопрос?\n",
      "after:  удалить свой вопрос\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q, rq in zip(questions[:5], raw_questions[:5]): print('before: {}\\nafter:  {}\\n'.format(rq, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что просто убирать пунктуацию не очень эффективно. Да и без стоп-слов вопросы с Ответов.Mailru кажутся полным бредом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk.data.load('tokenizers/punkt/russian.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем `TweetTokenizer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_question(raw_question, tokenizer = TweetTokenizer(), stopwords = None):\n",
    "    \"\"\"\n",
    "    raw_question: str\n",
    "    tokenizer: tokenizer, default: TweetTokenizer()\n",
    "    stopwords: list, default: None\n",
    "    \n",
    "    returns: list of str (tokenized question)\n",
    "    e.g.:\n",
    "        raw_question = Иисус это Вселенная?\n",
    "        returns ['иисус', 'это', 'вселенная', '?']     \n",
    "    \"\"\"\n",
    "    words = tokenizer.tokenize(raw_question.lower())\n",
    "                     \n",
    "    if stopwords:\n",
    "        words = [w for w in words if not w in stopwords]   \n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = [tokenize_question(q) for q in raw_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenses:  45571\n",
      "words:  524480\n",
      "unique words:  69346\n"
     ]
    }
   ],
   "source": [
    "print('sentenses: ', len(tokens))\n",
    "print('words: ', len([token for sent in tokens for token in sent]))\n",
    "print('unique words: ', len(set([token for sent in tokens for token in sent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кто', 'знает', 'сайты', ',', 'где', 'можно', 'качать', 'бесплатные', 'mp3', '?']\n",
      "['почему', 'так', 'часто', 'встречаються', 'люди', 'хамы', '?']\n",
      "['почему', 'ногти', 'на', 'больших', 'пальцах', 'рук', 'растут', 'медленнее', ',', 'чем', 'на', 'остальных', '(', 'указательном', ',', 'среднем', ',', 'безымянном', 'и', 'мизинце', ')', '?']\n",
      "['у', 'кого', 'есть', 'слайд-гитара', '?']\n",
      "['как', 'удалить', 'свой', 'вопрос', '?']\n"
     ]
    }
   ],
   "source": [
    "for t in tokens[:5]: print(str(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окей, выглядит неплохо, но там наверняка много мусора.\n",
    "\n",
    "* Добавим `reduce_len = True` (вместо 53893 уникальных слов мы получим 53881): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_reduce_len = [tokenize_question(q, TweetTokenizer(reduce_len = True)) \n",
    "                     for q in raw_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenses:  45571\n",
      "words:  524480\n",
      "unique words:  69330\n"
     ]
    }
   ],
   "source": [
    "print('sentenses: ', len(tokens_reduce_len))\n",
    "print('words: ', len([token for sent in tokens_reduce_len for token in sent]))\n",
    "print('unique words: ', len(set([token for sent in tokens_reduce_len for token in sent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "способствуетtttttt\n",
      "70000\n",
      "2024561111\n",
      "0xc0000005\n",
      "20000-25000\n",
      "150000тдол\n",
      "10000р\n",
      "zzzz\n",
      "40000р\n",
      "0,000011\n"
     ]
    }
   ],
   "source": [
    "for t in list(set([token for sent in tokens for token in sent])\n",
    "              .difference(set([token for sent in tokens_reduce_len for token in sent])))[:10]: print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Добавим `strip_handles = True` к `reduce_len = True` (вместо 53881 уникальных слов мы получим 53878). \n",
    "\n",
    "(Потеряются слова `{'@zakladkis', '@kiska', '@instagram'}`. На мой взгляд, особой важности в них не было.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_reduce_strip = [tokenize_question(q, TweetTokenizer(reduce_len    = True, \n",
    "                                                           strip_handles = True)) \n",
    "                       for q in raw_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenses:  45571\n",
      "words:  524474\n",
      "unique words:  69325\n"
     ]
    }
   ],
   "source": [
    "print('sentenses: ', len(tokens_reduce_strip))\n",
    "print('words: ', len([token for sent in tokens_reduce_strip for token in sent]))\n",
    "print('unique words: ', len(set([token for sent in tokens_reduce_strip for token in sent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@instagram\n",
      "@echo\n",
      "@zakladkis\n",
      "@kiska\n",
      "@medi\n"
     ]
    }
   ],
   "source": [
    "for t in (set([token for sent in tokens_reduce_len for token in sent])\n",
    "          .difference(set([token for sent in tokens_reduce_strip for token in sent]))): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_word(token):\n",
    "    return not re.search(r'^[\\w\\d\\-]+$', token) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_okay(token):\n",
    "    token_is_word  = is_word(token)\n",
    "    token_is_punct = token in [',', '-', ':']\n",
    "    \n",
    "    return token_is_word or token_is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# token_list = tokens_reduce_strip[67]\n",
    "# print(str(token_list))\n",
    "\n",
    "# for token in token_list: print(token, '\\t\\t\\t', re.search(r'^[\\w\\d\\-]+$' ,token) is None)\n",
    "# for token in token_list: print(token, '\\t\\t\\t', is_word(token))\n",
    "# for token in token_list: print(token, '\\t\\t', is_okay(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_tokenized = []\n",
    "\n",
    "for token_list in tokens_reduce_strip:\n",
    "    token_list_ok = [t for t in token_list if is_okay(t)]\n",
    "    question = ' '.join(token_list_ok)\n",
    "    questions_tokenized.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кто знает сайты , где можно качать бесплатные mp3\n",
      "почему так часто встречаються люди хамы\n",
      "почему ногти на больших пальцах рук растут медленнее , чем на остальных указательном , среднем , безымянном и мизинце\n",
      "у кого есть слайд-гитара\n",
      "как удалить свой вопрос\n"
     ]
    }
   ],
   "source": [
    "for q in questions_tokenized[:5]: print(str(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_space_before(string):\n",
    "    \"\"\"\n",
    "    string: str\n",
    "    returns: str (without spaces before commas and colons)\n",
    "    e.g.:\n",
    "        string = 'дять , а 2 провода которые вышли от транса куда уйдет'\n",
    "        returns 'дять, а 2 провода которые вышли от транса куда уйдет'\n",
    "    \"\"\"\n",
    "    s = re.sub(' ,', ',', string)\n",
    "    s = re.sub(' :', ':', s)\n",
    "    return  s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут марковчейн для развлечения, пока вопросы парсятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import markovify\n",
    "import pymarkovchain\n",
    "\n",
    "# mv = markovify.Text('\\n'.join(questions), state_size = 2)\n",
    "# for _ in range(50): print(mv.make_sentence(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc = pymarkovchain.MarkovChain()\n",
    "mc.generateDatabase('\\n'.join(questions_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- на нас были от сотрудников в гит?\n",
      "- что делать?\n",
      "- лучший?\n",
      "- людии, помогите вспомнить название британской сказки автор - женщина, с кем обсуждать биаса, дорамы и т д?\n",
      "- помогите пожалуйста?\n",
      "- как быть гуманным, если у меня гта 5 возможно как-то через торрент отправить папку, создал торрент файл но он про него?\n",
      "- ларгус установка бк?\n",
      "- как долго хватит gtx 1080 vga мониторы, не дотягиваюсь до звонка: что бы было по жоще, подскажите что даёт жизнь?\n",
      "- денег на фильтры?\n",
      "- стоит ли нести в юстировку 24-70 l ii, если ждать бесполезно?\n",
      "- верно говорят, она видела уверенного и физизески развитого?\n",
      "- сааб 9-5 2000 года, депрессия все время, что за культ жоп и кача в инстаграм вставить цифры в в москве вкусно, быстро, но тут так мало популярной французской музыки, серфинга по инету вообще реальная вещь?\n",
      "- где можно скачать?\n",
      "- собеседник меня не стало что делать нам?\n",
      "- почему мужчины после 50 такие потрепанный и помятые почему?\n",
      "- как спорт влияют на кашель?\n",
      "- хочу подать в суд уголовное дело если оно висяк или глухарь?\n",
      "- тиристор т125 - 9 - тке его срезают или высверлиаают?\n",
      "- тиковые данные forex?\n",
      "- жених 2016 года, пропустят ли по закону физики?\n",
      "- ваша даль на что сможете срочно?\n",
      "- стоит ли планировать день расставлять все цели, иначе огонь не будет учитываться при назначении пенсии?\n",
      "- как относитесь терпимо или ну их?\n",
      "- сократите дроби до несократимых дробей?\n",
      "- почему всё больше поднимается шум в аудио?\n",
      "- спишите, расставляя пропущеные знаки препинания правильно ли день рождения буквы ё?\n",
      "- потянет-ли obs если процессор intel core 2 в пятой?\n",
      "- геометрия, пожалуйста, уважаемые эксперты погадайте пожалуйста когда закончиться застой в делах неудач, когда вас все деньги, рублями?\n",
      "- девушки слишком большая клиентская база, мужчина ее может бросить в любой мороз?\n",
      "- есть подписчики где посмотреть фотки дочки анджелины джоли и бреда питта?\n",
      "- нуждаюсь в совете?\n",
      "- меняется цвет предмета на который при погружении в воду или же шагнуть прямо с земли?\n",
      "- на дорогее тает снег и грянули морозы арабы в шоке ведь я же изменил своим идеалам, а уже что?\n",
      "- пропускная способность некоторого канала связи равна 128 000 бит с сколько времени идет заказное письмо из департамента образования со следующим содержанием?\n",
      "- а приехав в питер, а как возвратить взорванную тачку в gta episodes from liberty city продать машину?\n",
      "- украинцы знают где находится станция?\n",
      "- зачем ждать 8 марта и 23 февраля?\n",
      "- почему манси так похожи на пытку?\n",
      "- вам верят?\n",
      "- когда у меня появится молодой человек, при онлайн заявке на дебетовую карту в альфа банке какие подводные камни меня ожидают и сравнивая с той же кукурузой?\n",
      "- наладится ли у джима керри фильмы, подобия фильма запретное царство?\n",
      "- какие причины и как лечебная трава?\n",
      "- высота 3корня39?\n",
      "- почему ляшко переживает о том, что на этот ноут wot asus f553ma - bing-sx 628b?\n",
      "- легален ли сайт в архиве примеры исходного кода, скриншотики?\n",
      "- а не деньги?\n",
      "- как правильно воспитывать дочь без отца?\n",
      "- пожалуйста химия 8 класс русский язык?\n",
      "- что он имел ввиду партнерш по бизнесу?\n",
      "- почему для воров и убийц лидером и героем является самый безсовестный и кровожадный вор и сказал что наблюдается шлак что это приведёт к потере данных на диске с?\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50): print('- ' + (remove_space_before(mc.generateString())) + '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
