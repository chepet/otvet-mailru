{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "\n",
    "import nltk\n",
    "from nltk import corpus\n",
    "from nltk.tokenize import TweetTokenizer, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48122\n"
     ]
    }
   ],
   "source": [
    "folder = 'questions'\n",
    "files = [file for file in os.listdir(folder) if file.endswith('.txt')]\n",
    "\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_questions = []\n",
    "\n",
    "for file in files:\n",
    "    with open(os.path.join(folder, file)) as f:\n",
    "        raw_questions.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save raw, unprocessed questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('raw_questions.txt', 'w') as f:\n",
    "    f.write('\\n'.join(raw_questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Кто знает сайты, где можно качать бесплатные mp3?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_questions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уберём пунктуацию и стоп-слова\n",
    "\n",
    "1\\. Пунктуация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "punctuation = '\"#$%&\\'()*+/:,-.?!;<=>@[\\]^_`{|}~'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# questions = [''.join([ch for ch in q if ch not in punctuation]).lower()  for q in raw_questions]\n",
    "# for q in questions[:5]: print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Уберём из предложений также стоп-слова из `nltk.corpus.stopwords.words('russian')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n",
      "['во', 'том', 'того', 'со', 'нас', 'вас', 'мне', 'то', 'для', 'моя', 'есть', 'про', 'зачем', 'другой', 'чтобы']\n"
     ]
    }
   ],
   "source": [
    "stopwords = list(set(corpus.stopwords.words('russian')))\n",
    "\n",
    "print(len(stopwords))\n",
    "print(str(stopwords[:15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raw_question_to_clean(raw_question, stopwords = stopwords):\n",
    "    \"\"\"\n",
    "    raw_question: str\n",
    "    stopwords: list of str\n",
    "    \n",
    "    returns: str (question without stopwords and punctuation)\n",
    "    e.g:\n",
    "        raw_question = 'С чем будет связана моя будущая работа? кем лучше стать? 25.09.1999'\n",
    "        returns 'связана будущая работа кем стать 25 09 1999'\n",
    "    \"\"\"\n",
    "    \n",
    "    letters_only = re.sub('[^a-zA-Zа-яА-я0-9]', ' ', raw_question) \n",
    "    \n",
    "    words = letters_only.lower().split()                                                  \n",
    "    meaningful_words = [w for w in words if not w in stopwords]   \n",
    "\n",
    "    return(' '.join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions = [raw_question_to_clean(q) for q in raw_questions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним почищенные (`questions`) и исходные, необработанные вопросы (`raw_questions`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: Кто знает сайты, где можно качать бесплатные mp3?\n",
      "after:  знает сайты качать бесплатные mp3\n",
      "\n",
      "before: почему так часто встречаються люди хамы?\n",
      "after:  почему часто встречаються люди хамы\n",
      "\n",
      "before: Почему ногти на больших пальцах рук растут медленнее, чем на остальных (указательном, среднем, безымянном и мизинце)?\n",
      "after:  почему ногти больших пальцах рук растут медленнее остальных указательном среднем безымянном мизинце\n",
      "\n",
      "before: у кого есть слайд-гитара?\n",
      "after:  кого слайд гитара\n",
      "\n",
      "before: как удалить свой вопрос?\n",
      "after:  удалить свой вопрос\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for q, rq in zip(questions[:5], raw_questions[:5]): print('before: {}\\nafter:  {}\\n'.format(rq, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что просто убирать пунктуацию не очень эффективно. Да и без стоп-слов вопросы с Ответов.Mailru кажутся полным бредом. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk.data.load('tokenizers/punkt/russian.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Попробуем `TweetTokenizer()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_question(raw_question, tokenizer = TweetTokenizer(), stopwords = None):\n",
    "    \"\"\"\n",
    "    raw_question: str\n",
    "    tokenizer: tokenizer, default: TweetTokenizer()\n",
    "    stopwords: list, default: None\n",
    "    \n",
    "    returns: list of str (tokenized question)\n",
    "    e.g.:\n",
    "        raw_question = Иисус это Вселенная?\n",
    "        returns ['иисус', 'это', 'вселенная', '?']     \n",
    "    \"\"\"\n",
    "    words = tokenizer.tokenize(raw_question.lower())\n",
    "                     \n",
    "    if stopwords:\n",
    "        words = [w for w in words if not w in stopwords]   \n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokens = [tokenize_question(q) for q in raw_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenses:  48122\n",
      "words:  555969\n",
      "unique words:  72122\n"
     ]
    }
   ],
   "source": [
    "print('sentenses: ', len(tokens))\n",
    "print('words: ', len([token for sent in tokens for token in sent]))\n",
    "print('unique words: ', len(set([token for sent in tokens for token in sent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['кто', 'знает', 'сайты', ',', 'где', 'можно', 'качать', 'бесплатные', 'mp3', '?']\n",
      "['почему', 'так', 'часто', 'встречаються', 'люди', 'хамы', '?']\n",
      "['почему', 'ногти', 'на', 'больших', 'пальцах', 'рук', 'растут', 'медленнее', ',', 'чем', 'на', 'остальных', '(', 'указательном', ',', 'среднем', ',', 'безымянном', 'и', 'мизинце', ')', '?']\n",
      "['у', 'кого', 'есть', 'слайд-гитара', '?']\n",
      "['как', 'удалить', 'свой', 'вопрос', '?']\n"
     ]
    }
   ],
   "source": [
    "for t in tokens[:5]: print(str(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Окей, выглядит неплохо, но там наверняка много мусора.\n",
    "\n",
    "* Добавим `reduce_len = True` (вместо 53893 уникальных слов мы получим 53881): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_reduce_len = [tokenize_question(q, TweetTokenizer(reduce_len = True)) \n",
    "                     for q in raw_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenses:  48122\n",
      "words:  555969\n",
      "unique words:  72105\n"
     ]
    }
   ],
   "source": [
    "print('sentenses: ', len(tokens_reduce_len))\n",
    "print('words: ', len([token for sent in tokens_reduce_len for token in sent]))\n",
    "print('unique words: ', len(set([token for sent in tokens_reduce_len for token in sent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaaa\n",
      "способствуетtttttt\n",
      "70000\n",
      "2024561111\n",
      "0xc0000005\n",
      "20000-25000\n",
      "150000тдол\n",
      "10000р\n",
      "zzzz\n",
      "40000р\n"
     ]
    }
   ],
   "source": [
    "for t in list(set([token for sent in tokens for token in sent])\n",
    "              .difference(set([token for sent in tokens_reduce_len for token in sent])))[:10]: print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Добавим `strip_handles = True` к `reduce_len = True` (вместо 53881 уникальных слов мы получим 53878). \n",
    "\n",
    "(Потеряются слова `{'@zakladkis', '@kiska', '@instagram'}`. На мой взгляд, особой важности в них не было.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_reduce_strip = [tokenize_question(q, TweetTokenizer(reduce_len    = True, \n",
    "                                                           strip_handles = True)) \n",
    "                       for q in raw_questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentenses:  48122\n",
      "words:  555962\n",
      "unique words:  72100\n"
     ]
    }
   ],
   "source": [
    "print('sentenses: ', len(tokens_reduce_strip))\n",
    "print('words: ', len([token for sent in tokens_reduce_strip for token in sent]))\n",
    "print('unique words: ', len(set([token for sent in tokens_reduce_strip for token in sent])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@instagram\n",
      "@echo\n",
      "@zakladkis\n",
      "@kiska\n",
      "@medi\n"
     ]
    }
   ],
   "source": [
    "for t in (set([token for sent in tokens_reduce_len for token in sent])\n",
    "          .difference(set([token for sent in tokens_reduce_strip for token in sent]))): print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_word(token):\n",
    "    return not re.search(r'^[\\w\\d\\-]+$', token) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_okay(token):\n",
    "    token_is_word  = is_word(token)\n",
    "    token_is_punct = token in [',', '-', ':']\n",
    "    \n",
    "    return token_is_word or token_is_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# token_list = tokens_reduce_strip[67]\n",
    "# print(str(token_list))\n",
    "\n",
    "# for token in token_list: print(token, '\\t\\t\\t', re.search(r'^[\\w\\d\\-]+$' ,token) is None)\n",
    "# for token in token_list: print(token, '\\t\\t\\t', is_word(token))\n",
    "# for token in token_list: print(token, '\\t\\t', is_okay(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_tokenized = []\n",
    "\n",
    "for token_list in tokens_reduce_strip:\n",
    "    token_list_ok = [t for t in token_list if is_okay(t)]\n",
    "    question = ' '.join(token_list_ok)\n",
    "    questions_tokenized.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "кто знает сайты , где можно качать бесплатные mp3\n",
      "почему так часто встречаються люди хамы\n",
      "почему ногти на больших пальцах рук растут медленнее , чем на остальных указательном , среднем , безымянном и мизинце\n",
      "у кого есть слайд-гитара\n",
      "как удалить свой вопрос\n"
     ]
    }
   ],
   "source": [
    "for q in questions_tokenized[:5]: print(str(q))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "А теперь попробуем повторить последовательность действий `tokenize (reduce, strip)`, `is_okay`, `join`, но не с цельными вопросами, как в прошлом случае, а с отдельными предложениями (т.е. если вопрос — «зачем? почему?», будем делать указанные выше действия для «зачем?» и для «почему?» по отдельности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "joined_questions = '\\n'.join(raw_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "questions_sent_tokenized = sent_tokenize(joined_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кто знает сайты, где можно качать бесплатные mp3?',\n",
       " 'почему так часто встречаються люди хамы?',\n",
       " 'Почему ногти на больших пальцах рук растут медленнее, чем на остальных (указательном, среднем, безымянном и мизинце)?',\n",
       " 'у кого есть слайд-гитара?',\n",
       " 'как удалить свой вопрос?',\n",
       " 'На чем собирать пазлы с большим и очень большим количеством элементов и куда их потом приклеивать?',\n",
       " 'Куда обратиться, чтобы отремонтировать ванную комнату?',\n",
       " 'в каком формате лучше скачивать музыку на MP3-player?',\n",
       " 'Кто такой рыжий ап?',\n",
       " 'Самые популярные виды спорта в России\\nСколько автозаправок в Москве?']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_sent_tokenized[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens_reduce_strip = [tokenize_question(q, TweetTokenizer(reduce_len    = True, \n",
    "                                                           strip_handles = True)) \n",
    "                       for q in questions_sent_tokenized]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительная обработка:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_space_before(string):\n",
    "    \"\"\"\n",
    "    string: str\n",
    "    returns: str (without spaces before commas and colons)\n",
    "    e.g.:\n",
    "        string = 'дять , а 2 провода которые вышли от транса куда уйдет'\n",
    "        returns 'дять, а 2 провода которые вышли от транса куда уйдет'\n",
    "    \"\"\"\n",
    "    s = re.sub(' ,', ',', string)\n",
    "    s = re.sub(' :', ':', s)\n",
    "    return  s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут марковчейн для развлечения, пока вопросы парсятся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import markovify\n",
    "import pymarkovchain\n",
    "\n",
    "# mv = markovify.Text('\\n'.join(questions), state_size = 2)\n",
    "# for _ in range(50): print(mv.make_sentence(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mc = pymarkovchain.MarkovChain()\n",
    "mc.generateDatabase('\\n'.join(questions_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- как создать готический сайт?\n",
      "- а она что на четвереньках, очень нужно?\n",
      "- васкогда нить фоткали когда вы поняли, что нужно готовить сына путина к федеральному собранию по отношению ко мне мужчина, какие еще знаки о рождении детей вы хотели изменить в системе увеличить?\n",
      "- срочно?\n",
      "- как накрутить часы в skyrim?\n",
      "- как выглядит грустный человек т е как его написать?\n",
      "- въ способнъ прощать и давать еще один ребус от меня надо?\n",
      "- почему так пишет?\n",
      "- америкосы столько врут, что дяди нет?\n",
      "- безбожное поколение потомков недобитых большевиков и коммунистов вновь готово громить православные храмы?\n",
      "- за это отдать?\n",
      "- что делать?\n",
      "- научите?\n",
      "- наш зато с колен без путина?\n",
      "- а как ты подпитываешь себя в зеркале другое где правда подскажите?\n",
      "- помогите пожалуйста я не из гдз?\n",
      "- транзисторы разных частот?\n",
      "- witcher enhanced edition ошибка при входе на карту придут ли они там размещаться?\n",
      "- а кто тогда такие орбы-плазмоиды, если будет лобовое столкновение?\n",
      "- поверхность земли 22 гр воздушный шар что вы надеетесь?\n",
      "- подчеркните вещества, составьте их список, невозможно достучатся?\n",
      "- поностальгируем немножко для тех кто тянет назад?\n",
      "- во сне того кто мечтает и стремится или у него появится мужчина которым будут отношения с девушкой парень максим 1992?\n",
      "- какой цвет выбрать?\n",
      "- как можно соревноваться с обдолбанными скотами?\n",
      "- какую экипировку надо покупать?\n",
      "- можно даты появления человеческой расы, библии и корана?\n",
      "- смерть диктатора, только на огне, который состоит в гильдии?\n",
      "- детализация звонков в личном на 2017 г?\n",
      "- составьте предложения к схемам пожалуйста?\n",
      "- почему из всех?\n",
      "- ну впрочем как всеглда перед тем как сьесть?\n",
      "- куда звонить?\n",
      "- какой валюте откладывать сбережения по 15-20 т р спасибо?\n",
      "- у пациента в первую очередь?\n",
      "- пойдет такая стрижка?\n",
      "- почему скорость интернета в hmailserver?\n",
      "- нестабильный пинг в кс го в пати, развалим кабины в мм?\n",
      "- какие то магические способности есть?\n",
      "- поедем ли в симс 3 ничего не удалится?\n",
      "- могут быть отношения?\n",
      "- в 14 раз то власть перестала сюсюкаться с нато долго же я сбил?\n",
      "- у вас имеется дома на всякий случай?\n",
      "- почему забыл академика кадырова?\n",
      "- почему государство не хочет в подарок?\n",
      "- мой семейный вопрос на засыпку реально ли там школьникам?\n",
      "- влюбилась знаменитость, которая считает, что делать если мужчина не делает попыток ее в постель?\n",
      "- а, у учителей?\n",
      "- какие затраты?\n",
      "- сочинение по плану описать реку амур?\n"
     ]
    }
   ],
   "source": [
    "for _ in range(50): print('- ' + (remove_space_before(mc.generateString())) + '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
